<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ashwinee Panda</title>

    <meta name="author" content="Ashwinee Panda">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ashwinee Panda
                </p>
                <p>
                  I am a Postdoctoral Fellow at <a href="https://www.trails.umd.edu/">UMD</a> working with <a href="https://twitter.com/tomgoldsteincs">Tom Goldstein</a> on LLMs.</p>
                  <p>
                  I received my PhD from <a href="https://princeton.edu/">Princeton University</a> working with <a href="https://www.princeton.edu/~pmittal/">Prateek Mittal</a>. 
                  <!-- My thesis was "Unlocking Trustworthy Machine Learning with Sparsity". -->
                <!-- My PhD was funded by <a href="https://gradschool.princeton.edu/financial-support/fellowships/princeton-fellowships/gordon-wu-fellowship">fellowships</a> and <a href="https://www.energy.gov/articles/department-energy-announces-67-million-iot-integration-research">grants</a>.  -->
                During my PhD, I received <a href="https://openai.com/blog/superalignment-fast-grants">the OpenAI Superalignment Fast Grant</a> for our work showing that <a href="https://openreview.net/forum?id=6Mxhg9PtDE">current safety alignment is shallow</a>, which received <a href="https://blog.iclr.cc/2025/04/22/announcing-the-outstanding-paper-awards-at-iclr-2025/">the Outstanding Paper Award at ICLR 2025</a>.
                <!-- Before Princeton I worked in <a href="https://rise.cs.berkeley.edu/">the UC Berkeley RISE Lab</a> where I was co-advised -->
                  <!-- by <a href="https://people.eecs.berkeley.edu/~jegonzal/">Joey Gonzalez</a> and <a href="https://people.eecs.berkeley.edu/~raluca/">Raluca Ada Popa</a>. -->
                
                <p>
                  If you are interested in working with me, send me a DM on Twitter.
                </p>
                <p style="text-align:center">
                  <a href="data/AshwineePandaCV_May2025.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=rFC3l6YAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/PandaAshwinee">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/kiddyboots216">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profpic_square.jpg"><img style="width:100%;max-width:100%;border-radius:50%;" alt="profile photo" src="images/profpic_square.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am currently working on a number of topics in LLMs. 
                  Right now I'm trying to understand how reasoning improves LLMs. 
                  Another big direction is in identifying what elements of the LLM pipeline are bottlenecking our scaling growth.
                  A lot of my research is conducted through the lens of sparsity. I was a lead organizer for <a href="https://www.sparsellm.org/">the ICLR 2025 workshop on Sparsity in LLMs</a>.
                  <!-- I have a series of papers on privacy: Privacy Auditing (ICLR 2025), Phishing (ICLR 2024), DP-ICL (ICLR 2024), DP-ZO (TMLR 2025), DP Scaling (ICML 2024), DP-RandP (NeurIPS 2023), DP-Diffusion (ICML 2023). -->
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/shallow_alignment.png" alt="deep alignment" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://openreview.net/forum?id=6Mxhg9PtDE">
                  <span class="papertitle">Safety Alignment Should be Made More Than Just a Few Tokens Deep
                  </span>
                </a>
                <br>
                Xiangyu Qi,
                <strong>Ashwinee Panda</strong>,
                Kaifeng Lyu,
                Xiao Ma,
                Subhrajit Roy,
                Ahmad Beirami,
                Prateek Mittal,
                Peter Henderson
                <br>
                At <em>ICLR 2025 (Outstanding Paper Award)</em>
                <br>
                <a href="https://openreview.net/forum?id=6Mxhg9PtDE">paper</a> /
                <a href="https://github.com/Unispac/shallow-vs-deep-alignment">code</a>
                <p>We analyze safety alignment and show that it is largely shallow. We propose methods for making it deeper.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/expertapprox.png" alt="Dense Backpropagation" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2504.12463">
                  <span class="papertitle">Dense Backpropagation Improves Training for Sparse Mixture-of-Experts
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Vatsal Baherwani,
                Zain Sarwar,
                Benjamin Therien,
                Supriyo Chakraborty,
                Tom Goldstein
                <br>
                <em>NeurIPS 2024 Workshops</em>
                <br>
                <a href="https://arxiv.org/abs/2504.12463">paper</a> /
                <a href="https://github.com/vatsal0/default-moe">code</a> /
                <a href="https://x.com/PandaAshwinee/status/1914124872802091428">thread</a>
                <p>We present a lightweight approximation method that gives the MoE router a dense gradient update while continuing to sparsely activate its parameters.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/vdit.png" alt="Video Diffusion Attention" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2504.10317">
                  <span class="papertitle">Analysis of Attention in Video Diffusion Transformers
                  </span>
                </a>
                <br>
                Yuxin Wen,
                Jim Wu,
                Ajay Jain,
                Tom Goldstein,
                <strong>Ashwinee Panda</strong>
                <br>
                <em>Arxiv 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2504.10317">paper</a> /
                <a href="https://tinyurl.com/vditattention">website</a> /
                <a href="https://x.com/PandaAshwinee/status/1912523804540100677">thread</a>
                <p>We conduct an in-depth analysis of attention in video diffusion transformers (VDiTs) and report a number of novel findings.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/auditing.png" alt="privacy auditing" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2503.06808">
                  <span class="papertitle">Privacy Auditing of Large Language Models
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda*</strong>,
                Xinyu Tang*,
                Milad Nasr,
                Christopher A. Choquette-Choo,
                Prateek Mittal
                <br>
                At <em>ICLR 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2503.06808">paper</a> /
                <a href="https://x.com/PandaAshwinee/status/1900182427651248559">thread</a>
                <p>We present the first method for doing privacy auditing of LLMs.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/gemstones_teaser.png" alt="gemstones" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="">
                  <span class="papertitle">Gemstones üíé: A Model Suite for Multi-Faceted Scaling Laws
                  </span>
                </a>
                <br>
                Sean McLeish,
                John Kirchenbauer,
                David Yu Miller,
                Siddharth Singh,
                Abhinav Bhatele,
                Micah Goldblum,
                <strong>Ashwinee Panda‚ô†Ô∏è</strong>,
                Tom Goldstein
                <br>
                At <em>ICLR 2025 Sci-FM</em>
                <br>
                <a href="https://arxiv.org/abs/2502.06857">paper</a> /
                <a href="https://github.com/mcleish7/gemstone-scaling-laws">code</a> /
                <a href="https://huggingface.co/collections/tomg-group-umd/gemstone-models-679408ee3f19f1d4d00e8b10">models</a> /
                <a href="https://mcleish7.github.io/gemstone-scaling-laws/">website</a> /
                <a href="https://x.com/PandaAshwinee/status/1897361636379533353">thread</a>
                <p>We release the Gemstone model suite for open-source scaling laws.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/attentionsink.jpeg" alt="Attention Sink Dormant Heads" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2504.03889">
                  <span class="papertitle">Using Attention Sinks to Identify and Evaluate Dormant Heads in Pretrained LLMs
                  </span>
                </a>
                <br>
                Pedro Sandoval-Segura,
                Xijun Wang,
                <strong>Ashwinee Panda</strong>,
                Micah Goldblum,
                Ronen Basri,
                Tom Goldstein,
                David Jacobs
                <br>
                <em>Arxiv 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2504.03889">paper</a> /
                <a href="https://x.com/psandovalsegura/status/1909652533334712691">thread</a>
                <p>We propose a new definition for attention heads dominated by attention sinks, known as dormant attention heads.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/lota.png" alt="lota" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2406.16797">
                  <span class="papertitle">Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Berivan Isik,
                Xiangyu Qi,
                Sanmi Koyejo,
                Tsachy Weissman,
                Prateek Mittal
                <br>
                At <em>ICML 2024 WANT (Best Paper) / ES-FoMO (Oral) </em>
                <br>
                <a href="https://arxiv.org/abs/2401.04343">paper</a> /
                <a href="https://github.com/kiddyboots216/lottery-ticket-adaptation/">code</a> /
                <a href="https://x.com/PandaAshwinee/status/1825571610230723027">thread</a>
                <p>Lottery Ticket Adaptation (LoTA) is a new adaptation method that handles challenging tasks, mitigates catastrophic forgetting, and enables model merging across different tasks.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dpzo.png" alt="dp zo" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2401.04343">
                  <span class="papertitle">Private Fine-tuning of Large Language Models with Zeroth-order Optimization
                  </span>
                </a>
                <br>
                Xinyu Tang*,
                <strong>Ashwinee Panda*</strong>,
                Milad Nasr*,
                Saeed Mahloujifar,
                Prateek Mittal
                <br>
                At <em>TMLR 2025, TPDP 2024 (Oral)</em>
                <br>
                <a href="https://arxiv.org/abs/2401.04343">paper</a>
                <p>We propose the first method for performing differentially private fine-tuning of large language models without backpropagation. Our method is the first to provide a nontrivial privacy-utility tradeoff under pure differential privacy.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dplinearscaling.png" alt="linear scaling" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2212.04486">
                  <span class="papertitle">A New Linear Scaling Rule for Private Adaptive Hyperparameter Optimization
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda*</strong>,
                Xinyu Tang*,
                Vikash Sehwag,
                Saeed Mahloujifar,
                Prateek Mittal
                <br>
                At <em>ICML 2024</em>
                <br>
                <a href="https://www.youtube.com/watch?v=KzxAP20TMJc&list=PLSIUOFhnxEiDoTNvhZWIm1PNBAFJWUxU8&index=6">talk</a> /
                <a href="https://arxiv.org/abs/2212.04486">paper</a> /
                <a href="https://github.com/kiddyboots216/dp-custom/">code</a>
                <p>We find that using scaling laws for Differentially Private Hyperparameter Optimization significantly outperforms prior work in privacy and compute cost.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/phishingfigure.png" alt="gpt phish" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1749190096987853023">
                  <span class="papertitle">Teach LLMs to Phish: Stealing Private Information from Language Models
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Christopher A. Choquette-Choo,
                Zhengming Zhang,
                Yaoqing Yang,
                Prateek Mittal
                <br>
                At <em>ICLR 2024</em>
                <br>
                <a href="https://www.youtube.com/watch?v=Tyw51pIp_gg&list=PLSIUOFhnxEiDoTNvhZWIm1PNBAFJWUxU8&index=2">talk</a> /
                <a href="https://arxiv.org/abs/2403.00871">paper</a> /
                <a href="https://x.com/PandaAshwinee/status/1749190096987853023">thread</a>
                <p>We propose a new practical data extraction attack that we call "neural phishing". This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Pipeline.png" alt="dp icl" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1747655539168059464">
                  <span class="papertitle">Privacy-Preserving In-Context Learning for Large Language Models</span>
                </a>
                <br>
                Tong Wu*,
                <strong>Ashwinee Panda*</strong>,
                Tianhao Wang*,
                Prateek Mittal
                <br>
                At <em>ICLR 2024</em>
                <br>
                <a href="https://www.youtube.com/watch?v=Tyw51pIp_gg&list=PLSIUOFhnxEiDoTNvhZWIm1PNBAFJWUxU8&index=2">talk</a> /
                <a href="https://arxiv.org/abs/2305.01639">paper</a> /
                <a href="https://github.com/tongwu2020/DP-ICL">code</a> /
                <a href="https://x.com/PandaAshwinee/status/1747655539168059464">thread</a>
                <p>We propose the first method for performing differentially private in-context learning. Our method generates sentences from in-context learning while keeping the in-context exemplars differentially private, that can be applied to blackbox APIs (ex RAG).</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/vlm.jpg" alt="VLM" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1673948702397046786">
                  <span class="papertitle">Visual Adversarial Examples Jailbreak Aligned Large Language Models
                  </span>
                </a>
                <br>
                Xiangyu Qi*,
                Kaixuan Huang*,
                <strong>Ashwinee Panda</strong>,
                Peter Henderson,
                Mengdi Wang,
                Prateek Mittal
                <br>
                At <em>AAAI 2024 (Oral)</em>
                <br>
                <a href="https://arxiv.org/abs/2306.13213">paper</a> /
                <a href="https://github.com/Unispac/Visual-Adversarial-Examples-Jailbreak-Large-Language-Models">code</a>
                <p>We propose the first method for generating visual adversarial examples that can serve as transferrable universal jailbreaks against aligned large language models.</p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dprandp.jpg" alt="dp random priors" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1668343271691816962">
                  <span class="papertitle">Differentially Private Image Classification by Learning Priors from Random Processes</span>
                </a>
                <br>
                Xinyu Tang*,
                <strong>Ashwinee Panda*</strong>,
                Vikash Sehwag,
                Prateek Mittal
                <br>
                At <em>NeurIPS 2023 (Spotlight)</em>
                <br>
                <a href="https://arxiv.org/abs/2306.06076">paper</a> /
                <a href="https://github.com/inspire-group/DP-RandP">code</a>
                <p>We pretrain networks with synthetic images that have strong performance on downstream private computer vision tasks.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dpdiffusion.jpg" alt="dp diffusion" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1s5wI9A-z4OBmucL5IVVFwx9hCZqfYsWX/view?usp=sharing">
                  <span class="papertitle">Differentially Private Generation of High Fidelity Samples From Diffusion Models</span>
                </a>
                <br>
                Vikash Sehwag*,
                <strong>Ashwinee Panda*</strong>,
                Ashwini Pokle,
                Xinyu Tang,
                Saeed Mahloujifar,
                Mung Chiang,
                J Zico Kolter,
                Prateek Mittal
                <br>
                At <em>ICML 2023</em> GenAI Workshop
                <br>
                <a href="https://openreview.net/pdf?id=vuVGcl0ed1">paper</a> /
                <a href="https://drive.google.com/file/d/1s5wI9A-z4OBmucL5IVVFwx9hCZqfYsWX/view?usp=sharing">poster</a>
                <p>We generate differentially private images from non-privately trained diffusion models by analyzing the inherent privacy of stochastic sampling.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/neurotoxin.jpg" alt="neurotoxin" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://proceedings.mlr.press/v162/zhang22w">
                  <span class="papertitle">Neurotoxin: Durable Backdoors in Federated Learning</span>
                </a>
                <br>
                Zhengming Zhang*,
                <strong>Ashwinee Panda*</strong>,
                Linyue Song,
                Yaoqing Yang,
                Prateek Mittal,
                Joseph Gonzalez,
                Kannan Ramchandran,
                Michael Mahoney
                <br>
                In <em>ICML 2022 (Spotlight)</em>
                <br>
                <a href="https://arxiv.org/abs/2206.10341">paper</a> /
                <a href="https://drive.google.com/file/d/1sDu_5xWNzU20dleDJWC5JThXtn5BLJLL/view?usp=sharing">poster</a> /
                <a href="https://github.com/jhcknzzm/Federated-Learning-Backdoor">code</a>
                <p>Neurotoxin is a novel model poisoning attack for federated learning that stays present in the system for up to 5X longer than the baseline attack.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/sparsefed.jpg" alt="sparsefed" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://proceedings.mlr.press/v151/panda22a.html">
                  <span class="papertitle">SparseFed: Mitigating Model Poisoning Attacks in Federated Learning via Sparsification</span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Saeed Mahloujifar,
                Arjun Bhagoji,
                Supriyo Chakraborty,
                Prateek Mittal
                <br>
                In <em>AISTATS 2022</em>
                <br>
                <a href="https://arxiv.org/abs/2112.06274">paper</a> /
                <a href="https://github.com/kiddyboots216/CommEfficient/tree/attacks">code</a>
                <p>SparseFed is a provably robust defense against model poisoning attacks in federated learning that uses server-side sparsification to avoid updating malicious neurons.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/fetchsgd.jpg" alt="fetchsgd" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://proceedings.mlr.press/v119/rothchild20a.html">
                  <span class="papertitle">FetchSGD: Communication-Efficient Federated Learning with Sketching</span>
                </a>
                <br>
                Daniel Rothchild*,
                <strong>Ashwinee Panda*</strong>,
                Enayat Ullah,
                Nikita Ivkin,
                Ion Stoica,
                Vladimir Braverman,
                Joseph Gonzalez,
                Raman Arora
                <br>
                In <em>ICML 2020</em>
                <br>
                <a href="https://arxiv.org/abs/2007.07682">paper</a> /
                <a href="https://github.com/kiddyboots216/CommEfficient">code</a>
                <p>FetchSGD is a communication-efficient federated learning algorithm that compresses gradient updates with sketches.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/softpbt.jpg" alt="softpbt" width="160" style="border-style: none">             
                <td width="75%" valign="middle">
                  <a href="https://github.com/kiddyboots216/SoftPBT/blob/master/ICLR_2020___SoftPBT%20(2).pdf">
                    <span class="papertitle">SoftPBT: Leveraging Experience Replay for Efficient Hyperparameter Schedule Search</span>
                  </a>
                  <br>
                  <strong>Ashwinee Panda</strong>,
                  Eric Liang,
                  Richard Liaw,
                  Joey Gonzalez
                  <br>
                  <!-- Submitted to <em>NeurIPS 2019</em>
                  <br> -->
                  <a href="https://github.com/kiddyboots216/SoftPBT/blob/master/ICLR_2020___SoftPBT%20(2).pdf">paper</a> /
                  <a href="https://github.com/kiddyboots216/SoftPBT">code</a>
              
              

            </tbody></table>
                
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Not Research</h2>
                <p style="text-align:center">
                  <a href="data/AshwineePanda-bio.txt">WeChat</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ashwineepanda/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://www.instagram.com/ashwineepanda/">Instagram</a> &nbsp;/&nbsp;
                  <a href="https://www.yelp.com/user_details_reviews_self?userid=X1HlGDvL3RElFC9JiWQpyA">Yelp</a> &nbsp;/&nbsp;
                  <a href="https://www.goodreads.com/user/show/18314561-ashwinee">Goodreads</a>&nbsp;/&nbsp;
                  <a href="https://open.spotify.com/playlist/4z3RNRCOyFHHyfKi98LCYE?si=1a05c22007814de6">Spotify</a>
                </p>
                <p>
                  <a href="https://en.wikipedia.org/wiki/San_Jose,_California">I've</a> 
                  <a href="https://en.wikipedia.org/wiki/Berkeley,_California">lived</a> 
                  <a href="https://en.wikipedia.org/wiki/Princeton,_New_Jersey">all</a> 
                  <a href="https://en.wikipedia.org/wiki/New_York_City">over</a> 
                  <a href="https://en.wikipedia.org/wiki/Washington,_D.C.">America;</a>
                  <!-- I've lived all over America,  -->
                  feel free to ask me for food recs in <a href="https://www.instagram.com/stories/highlights/18124010734224361/">NYC</a>, <a href="https://www.instagram.com/stories/highlights/17920690429823023/">LA</a>, the SF Bay Area, or the DMV. 
                  <!-- I <a href="https://www.instagram.com/p/CYL9kQBLvSa/">frequently</a> <a href="https://www.instagram.com/p/CQ-MDOCt_H0/">go on</a> <a href="https://www.instagram.com/p/CSCqLZPpe3J/?img_index=1">food</a> <a href="https://www.instagram.com/p/Bj3S6cmHAu3/?img_index=1">tours</a>. Feel free to ask me for restaurant recs in NYC, Edison, San Francisco, Los Angeles, and the DMV.</li> -->
                  <!-- In high school I <a href="https://www.facebook.com/MathCompanions">taught math</a>, <a href="https://www.facebook.com/evhs.marching.band/">played sax</a>, <a href="https://www.evsd.club/">argued vociferously</a>,  <a href="https://evergreenvalleyhigh.esuhsd.org/students/performing-arts/drama">sang</a>, <a href="https://www.instagram.com/evhsjunoon/">danced</a>, and <a href="https://www.csssa.ca.gov/">wrote</a> <a href="https://www.facebook.com/groups/186416404874189">slam poetry</a>. -->
                  <!-- Before studying EECS at Cal I <a href="https://www.instagram.com/p/BJHa-uaBmYz/">spent the summer in China</a> working at <a href="https://www.dosepacker.com/">a robotics company</a>.  -->
                  <!-- I've been back a <a href="https://www.instagram.com/p/BrJxJcfnEhF/">couple</a> <a href ="https://www.instagram.com/p/BrZSCucHVOI/?img_index=1">times</a>. -->
                </p>
                <p>
                  While at Berkeley I founded <a href="https://discreetai.com/">DiscreetAI</a> (now inactive), a <a href="https://www.samsungnext.com/">venture-backed</a> startup building <a href="https://github.com/DiscreetAI/decentralized-ml">privacy-preserving machine learning as-a-service</a>. You can check out <a href="https://www.producthunt.com/products/npm#discreetai">our ProductHunt launch</a> or <a href="https://github.com/discreetai">our GitHub</a> for more information. Among <a href="https://newsroom.haas.berkeley.edu/startups-pitch-win-2018-launch-finals/">other things</a> we won the <a href="https://www.instagram.com/p/BhvgMoDBh6L/?img_index=3">first YCombinator Hackathon</a> and built <a href="https://github.com/DiscreetAI/discreetai-chatbot">federated learning solutions</a> for <a href="https://www.ford.com/">Fortune 500 companies</a>.
                </p>
              
          <!-- <ul> -->
                <p>
                I read a lot and post my thoughts on Twitter and Goodreads. 
                <li><a href="https://x.com/PandaAshwinee/status/1759441743026491710">2024; Twitter thread of all books read</a></li> 
                <li><a href="https://x.com/PandaAshwinee/status/1739934767720657222">2023; ELO rating tierlist (72 books)</a></li> 
                <li><a href="https://www.goodreads.com/user/year_in_books/2021/18314561">2021; Goodreads year in review (100 books)</a></li>
              </p>
                <!-- <li> I <a href="https://www.instagram.com/p/Bm682-OH7MT/?img_index=1">gave a lecture</a> on <a href="https://www.su18.eecs70.org/static/slides/lec-31-handout.pdf">hashing</a> for CS70, UC Berkeley's undergraduate discrete mathematics and probability course. I have served on course staff for Cal's CS70 and CS189, and Princeton's COS432.</li> -->
                <!-- <li> I <a href="https://scet.berkeley.edu/blockchain-roundtable/">worked on R&D</a> at <a href="https://blockchain.berkeley.edu/">Blockchain at Berkeley</a>. I don't work in crypto anymore, but I'm happy to direct you to any of my amazing friends who have started companies in the space.</li> -->
                <!-- <li> I read voraciously, about <a href="https://www.goodreads.com/user/year_in_books/2021/18314561">100 books a year</a>, almost entirely fiction. My favorite genres are <a href="https://en.wikipedia.org/wiki/Xianxia">xianxia</a>, <a href="https://en.wikipedia.org/wiki/Hugo_Award_for_Best_Novel">SFF</a> and <a href ="https://www.reddit.com/r/horrorlit/">horror</a>. My favorite book is <a href="https://www.instagram.com/stories/highlights/17955811226448825/">The Brothers Karamazov</a> by Fyodor Dostoevsky. </li> -->
              <!-- </ul> -->
              </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                  <td style="padding:0px">
                    <br>
                    <p style="text-align:right;font-size:small;">
                      Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                    </p>
                  </td>
                </tr>
              </tbody></table>
            </td>
          </tr>
        </table>
      </body>
    </html>
