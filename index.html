<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ashwinee Panda</title>

    <meta name="author" content="Ashwinee Panda">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ashwinee Panda
                </p>
                <p>
                  I am a Postdoctoral Fellow at <a href="https://www.trails.umd.edu/">UMD</a> working with <a href="https://twitter.com/tomgoldsteincs">Tom Goldstein</a>. </p>
                  <p>
                  I received my PhD from <a href="https://princeton.edu/">Princeton University</a> working with <a href="https://www.princeton.edu/~pmittal/">Prateek Mittal</a>. My thesis was "Unlocking Trustworthy Machine Learning with Sparsity".
                My PhD was funded by <a href="https://gradschool.princeton.edu/financial-support/fellowships/princeton-fellowships/gordon-wu-fellowship">fellowships</a> and <a href="https://www.energy.gov/articles/department-energy-announces-67-million-iot-integration-research">grants</a> , most recently <a href="https://openai.com/blog/superalignment-fast-grants">the OpenAI Superalignment Fast Grant.</a>
                Before Princeton I worked in <a href="https://rise.cs.berkeley.edu/">the UC Berkeley RISE Lab</a> where I was co-advised
                  by <a href="https://people.eecs.berkeley.edu/~jegonzal/">Joey Gonzalez</a> and <a href="https://people.eecs.berkeley.edu/~raluca/">Raluca Ada Popa</a>.
                
                <p>
                  If you are interested in working with me, send me a DM on Twitter.
                </p>
                <p style="text-align:center">
                  <a href="data/AshwineePandaCV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=rFC3l6YAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/PandaAshwinee">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/kiddyboots216">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profpic_square.jpg"><img style="width:100%;max-width:100%;border-radius:50%;" alt="profile photo" src="images/profpic_square.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am currently working on a number of topics in LLM pretraining. I'm particularly interested in MoEs, scaling laws, and scalable low-resource decentralized training. I previously worked primarily on trustworthiness, mostly privacy and AI safety.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/expertapprox.png" alt="lota" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="">
                  <span class="papertitle">Dense Backpropagation Improves Routing for Sparsely-Gated Mixture-of-Experts
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda*</strong>,
                Vatsal Baherwani*,
                Zain Sarwar,
                Benjamin Therien,
                Supriyo Chakraborty,
                Tom Goldstein
                <br>
                At <em>NeurIPS 2024 OPT / ENSLP / Compression</em>
                <br>
                <p>We propose a new method for performing a dense gradient update on MoEs while still doing sparse forward passes.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/lota.png" alt="lota" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2406.16797">
                  <span class="papertitle">Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Berivan Isik,
                Xiangyu Qi,
                Sanmi Koyejo,
                Tsachy Weissman,
                Prateek Mittal
                <br>
                At <em>ICML 2024 ES-FoMO (Oral) / FM-Wild (Best Paper)</em>
                <br>
                <a href="https://arxiv.org/abs/2401.04343">paper</a> /
                <a href="https://github.com/kiddyboots216/lottery-ticket-adaptation/">code</a> /
                <a href="https://x.com/PandaAshwinee/status/1825571610230723027">thread</a>
                <p>Lottery Ticket Adaptation (LoTA) is a new adaptation method that handles challenging tasks, mitigates catastrophic forgetting, and enables model merging across different tasks.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/auditing.png" alt="privacy auditing" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://openreview.net/attachment?id=JlAwAMJT5P&name=pdf">
                  <span class="papertitle">Private Auditing of Large Language Models
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda*</strong>,
                Xinyu Tang*,
                Milad Nasr,
                Christopher A. Choquette-Choo,
                Prateek Mittal
                <br>
                At <em>ICML 2024 NextGenAISafety (Oral)</em>
                <br>
                <a href="https://openreview.net/attachment?id=JlAwAMJT5P&name=pdf">paper</a> 
                <p>We present the first method for doing privacy auditing of LLMs.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dpzo.png" alt="dp zo" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2401.04343">
                  <span class="papertitle">Private Fine-tuning of Large Language Models with Zeroth-order Optimization
                  </span>
                </a>
                <br>
                Xinyu Tang*,
                <strong>Ashwinee Panda*</strong>,
                Milad Nasr*,
                Saeed Mahloujifar,
                Prateek Mittal
                <br>
                At <em>TPDP 2024 (Oral)</em>
                <br>
                <a href="https://arxiv.org/abs/2401.04343">paper</a>
                <p>We propose the first method for performing differentially private fine-tuning of large language models without backpropagation. Our method is the first to provide a nontrivial privacy-utility tradeoff under pure differential privacy.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dplinearscaling.png" alt="linear scaling" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2212.04486">
                  <span class="papertitle">A New Linear Scaling Rule for Private Adaptive Hyperparameter Optimization
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda*</strong>,
                Xinyu Tang*,
                Vikash Sehwag,
                Saeed Mahloujifar,
                Prateek Mittal
                <br>
                At <em>ICML 2024</em>
                <br>
                <a href="https://www.youtube.com/watch?v=KzxAP20TMJc&list=PLSIUOFhnxEiDoTNvhZWIm1PNBAFJWUxU8&index=6">talk</a> /
                <a href="https://arxiv.org/abs/2212.04486">paper</a> /
                <a href="https://github.com/kiddyboots216/dp-custom/">code</a>
                <p>We find that using scaling laws for Differentially Private Hyperparameter Optimization significantly outperforms prior work in privacy and compute cost.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/phishingfigure.png" alt="gpt phish" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1749190096987853023">
                  <span class="papertitle">Teach LLMs to Phish: Stealing Private Information from Language Models
                  </span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Christopher A. Choquette-Choo,
                Zhengming Zhang,
                Yaoqing Yang,
                Prateek Mittal
                <br>
                At <em>ICLR 2024</em>
                <br>
                <a href="https://www.youtube.com/watch?v=Tyw51pIp_gg&list=PLSIUOFhnxEiDoTNvhZWIm1PNBAFJWUxU8&index=2">talk</a> /
                <a href="https://arxiv.org/abs/2403.00871">paper</a> /
                <a href="https://x.com/PandaAshwinee/status/1749190096987853023">thread</a>
                <p>We propose a new practical data extraction attack that we call "neural phishing". This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Pipeline.png" alt="dp icl" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1747655539168059464">
                  <span class="papertitle">Privacy-Preserving In-Context Learning for Large Language Models</span>
                </a>
                <br>
                Tong Wu*,
                <strong>Ashwinee Panda*</strong>,
                Tianhao Wang*,
                Prateek Mittal
                <br>
                At <em>ICLR 2024</em>
                <br>
                <a href="https://www.youtube.com/watch?v=Tyw51pIp_gg&list=PLSIUOFhnxEiDoTNvhZWIm1PNBAFJWUxU8&index=2">talk</a> /
                <a href="https://arxiv.org/abs/2305.01639">paper</a> /
                <a href="https://github.com/tongwu2020/DP-ICL">code</a> /
                <a href="https://x.com/PandaAshwinee/status/1747655539168059464">thread</a>
                <p>We propose the first method for performing differentially private in-context learning. Our method generates sentences from in-context learning while keeping the in-context exemplars differentially private, that can be applied to blackbox APIs (ex RAG).</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/vlm.jpg" alt="VLM" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1673948702397046786">
                  <span class="papertitle">Visual Adversarial Examples Jailbreak Aligned Large Language Models
                  </span>
                </a>
                <br>
                Xiangyu Qi*,
                Kaixuan Huang*,
                <strong>Ashwinee Panda</strong>,
                Peter Henderson,
                Mengdi Wang,
                Prateek Mittal
                <br>
                At <em>AAAI 2024 (Oral)</em>
                <br>
                <a href="https://arxiv.org/abs/2306.13213">paper</a> /
                <a href="https://github.com/Unispac/Visual-Adversarial-Examples-Jailbreak-Large-Language-Models">code</a>
                <p>We propose the first method for generating visual adversarial examples that can serve as transferrable universal jailbreaks against aligned large language models.</p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dprandp.jpg" alt="dp random priors" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://twitter.com/PandaAshwinee/status/1668343271691816962">
                  <span class="papertitle">Differentially Private Image Classification by Learning Priors from Random Processes</span>
                </a>
                <br>
                Xinyu Tang*,
                <strong>Ashwinee Panda*</strong>,
                Vikash Sehwag,
                Prateek Mittal
                <br>
                At <em>NeurIPS 2023 (Spotlight)</em>
                <br>
                <a href="https://arxiv.org/abs/2306.06076">paper</a> /
                <a href="https://github.com/inspire-group/DP-RandP">code</a>
                <p>We pretrain networks with synthetic images that have strong performance on downstream private computer vision tasks.</p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dpdiffusion.jpg" alt="dp diffusion" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1s5wI9A-z4OBmucL5IVVFwx9hCZqfYsWX/view?usp=sharing">
                  <span class="papertitle">Differentially Private Generation of High Fidelity Samples From Diffusion Models</span>
                </a>
                <br>
                Vikash Sehwag*,
                <strong>Ashwinee Panda*</strong>,
                Ashwini Pokle,
                Xinyu Tang,
                Saeed Mahloujifar,
                Mung Chiang,
                J Zico Kolter,
                Prateek Mittal
                <br>
                At <em>ICML 2023</em> GenAI Workshop
                <br>
                <a href="https://openreview.net/pdf?id=vuVGcl0ed1">paper</a> /
                <a href="https://drive.google.com/file/d/1s5wI9A-z4OBmucL5IVVFwx9hCZqfYsWX/view?usp=sharing">poster</a>
                <p>We generate differentially private images from non-privately trained diffusion models by analyzing the inherent privacy of stochastic sampling.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/neurotoxin.jpg" alt="neurotoxin" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://proceedings.mlr.press/v162/zhang22w">
                  <span class="papertitle">Neurotoxin: Durable Backdoors in Federated Learning</span>
                </a>
                <br>
                Zhengming Zhang*,
                <strong>Ashwinee Panda*</strong>,
                Linyue Song,
                Yaoqing Yang,
                Prateek Mittal,
                Joseph Gonzalez,
                Kannan Ramchandran,
                Michael Mahoney
                <br>
                In <em>ICML 2022 (Spotlight)</em>
                <br>
                <a href="https://arxiv.org/abs/2206.10341">paper</a> /
                <a href="https://drive.google.com/file/d/1sDu_5xWNzU20dleDJWC5JThXtn5BLJLL/view?usp=sharing">poster</a> /
                <a href="https://github.com/jhcknzzm/Federated-Learning-Backdoor">code</a>
                <p>Neurotoxin is a novel model poisoning attack for federated learning that stays present in the system for up to 5X longer than the baseline attack.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/sparsefed.jpg" alt="sparsefed" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://proceedings.mlr.press/v151/panda22a.html">
                  <span class="papertitle">SparseFed: Mitigating Model Poisoning Attacks in Federated Learning via Sparsification</span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Saeed Mahloujifar,
                Arjun Bhagoji,
                Supriyo Chakraborty,
                Prateek Mittal
                <br>
                In <em>AISTATS 2022</em>
                <br>
                <a href="https://arxiv.org/abs/2112.06274">paper</a> /
                <a href="https://github.com/kiddyboots216/CommEfficient/tree/attacks">code</a>
                <p>SparseFed is a provably robust defense against model poisoning attacks in federated learning that uses server-side sparsification to avoid updating malicious neurons.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/fetchsgd.jpg" alt="fetchsgd" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://proceedings.mlr.press/v119/rothchild20a.html">
                  <span class="papertitle">FetchSGD: Communication-Efficient Federated Learning with Sketching</span>
                </a>
                <br>
                Daniel Rothchild*,
                <strong>Ashwinee Panda*</strong>,
                Enayat Ullah,
                Nikita Ivkin,
                Ion Stoica,
                Vladimir Braverman,
                Joseph Gonzalez,
                Raman Arora
                <br>
                In <em>ICML 2020</em>
                <br>
                <a href="https://arxiv.org/abs/2007.07682">paper</a> /
                <a href="https://github.com/kiddyboots216/CommEfficient">code</a>
                <p>FetchSGD is a communication-efficient federated learning algorithm that compresses gradient updates with sketches.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/softpbt.jpg" alt="softpbt" width="160" style="border-style: none">
              </td>             
              <td width="75%" valign="middle">
                <a href="https://github.com/kiddyboots216/SoftPBT/blob/master/ICLR_2020___SoftPBT%20(2).pdf">
                  <span class="papertitle">SoftPBT: Leveraging Experience Replay for Efficient Hyperparameter Schedule Search</span>
                </a>
                <br>
                <strong>Ashwinee Panda</strong>,
                Eric Liang,
                Richard Liaw,
                Joey Gonzalez
                <br>
                <!-- Submitted to <em>NeurIPS 2019</em>
                <br> -->
                <a href="https://github.com/kiddyboots216/SoftPBT/blob/master/ICLR_2020___SoftPBT%20(2).pdf">paper</a> /
                <a href="https://github.com/kiddyboots216/SoftPBT">code</a>
            
            

          </tbody></table>
              
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Not Research</h2>
                <p style="text-align:center">
                  <a href="data/AshwineePanda-bio.txt">WeChat</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ashwineepanda/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://www.instagram.com/ashwineepanda/">Instagram</a> &nbsp;/&nbsp;
                  <a href="https://www.yelp.com/user_details_reviews_self?userid=X1HlGDvL3RElFC9JiWQpyA">Yelp</a> &nbsp;/&nbsp;
                  <a href="https://www.goodreads.com/user/show/18314561-ashwinee">Goodreads</a>&nbsp;/&nbsp;
                  <a href="https://open.spotify.com/playlist/4z3RNRCOyFHHyfKi98LCYE?si=1a05c22007814de6">Spotify</a>
                </p>
                <p>
                  <a href="https://en.wikipedia.org/wiki/San_Jose,_California">I've</a> 
                  <a href="https://en.wikipedia.org/wiki/Berkeley,_California">lived</a> 
                  <a href="https://en.wikipedia.org/wiki/Princeton,_New_Jersey">all</a> 
                  <a href="https://en.wikipedia.org/wiki/New_York_City">over</a> 
                  <a href="https://en.wikipedia.org/wiki/Washington,_D.C.">America;</a>
                  <!-- I've lived all over America,  -->
                  feel free to ask me for food recs in <a href="https://www.instagram.com/stories/highlights/18124010734224361/">NYC</a>, <a href="https://www.instagram.com/stories/highlights/17920690429823023/">LA</a>, the SF Bay Area, or the DMV. 
                  <!-- I <a href="https://www.instagram.com/p/CYL9kQBLvSa/">frequently</a> <a href="https://www.instagram.com/p/CQ-MDOCt_H0/">go on</a> <a href="https://www.instagram.com/p/CSCqLZPpe3J/?img_index=1">food</a> <a href="https://www.instagram.com/p/Bj3S6cmHAu3/?img_index=1">tours</a>. Feel free to ask me for restaurant recs in NYC, Edison, San Francisco, Los Angeles, and the DMV.</li> -->
                  <!-- In high school I <a href="https://www.facebook.com/MathCompanions">taught math</a>, <a href="https://www.facebook.com/evhs.marching.band/">played sax</a>, <a href="https://www.evsd.club/">argued vociferously</a>,  <a href="https://evergreenvalleyhigh.esuhsd.org/students/performing-arts/drama">sang</a>, <a href="https://www.instagram.com/evhsjunoon/">danced</a>, and <a href="https://www.csssa.ca.gov/">wrote</a> <a href="https://www.facebook.com/groups/186416404874189">slam poetry</a>. -->
                  <!-- Before studying EECS at Cal I <a href="https://www.instagram.com/p/BJHa-uaBmYz/">spent the summer in China</a> working at <a href="https://www.dosepacker.com/">a robotics company</a>.  -->
                  <!-- I've been back a <a href="https://www.instagram.com/p/BrJxJcfnEhF/">couple</a> <a href ="https://www.instagram.com/p/BrZSCucHVOI/?img_index=1">times</a>. -->
                </p>
                <p>
                  While at Berkeley I founded <a href="https://discreetai.com/">DiscreetAI</a> (now inactive), a <a href="https://www.samsungnext.com/">venture-backed</a> startup building <a href="https://github.com/DiscreetAI/decentralized-ml">privacy-preserving machine learning as-a-service</a>. You can check out <a href="https://www.producthunt.com/products/npm#discreetai">our ProductHunt launch</a> or <a href="https://github.com/discreetai">our GitHub</a> for more information. Among <a href="https://newsroom.haas.berkeley.edu/startups-pitch-win-2018-launch-finals/">other things</a> we won the <a href="https://www.instagram.com/p/BhvgMoDBh6L/?img_index=3">first YCombinator Hackathon</a> and built <a href="https://github.com/DiscreetAI/discreetai-chatbot">federated learning solutions</a> for <a href="https://www.ford.com/">Fortune 500 companies</a>.
                </p>
              
          <!-- <ul> -->
            <p>
            I read a lot and post my thoughts on Twitter and Goodreads. 
            <li><a href="https://x.com/PandaAshwinee/status/1759441743026491710">2024; Twitter thread of all books read</a></li> 
            <li><a href="https://x.com/PandaAshwinee/status/1739934767720657222">2023; ELO rating tierlist (72 books)</a></li> 
            <li><a href="https://www.goodreads.com/user/year_in_books/2021/18314561">2021; Goodreads year in review (100 books)</a></li>
          </p>
            <!-- <li> I <a href="https://www.instagram.com/p/Bm682-OH7MT/?img_index=1">gave a lecture</a> on <a href="https://www.su18.eecs70.org/static/slides/lec-31-handout.pdf">hashing</a> for CS70, UC Berkeley's undergraduate discrete mathematics and probability course. I have served on course staff for Cal's CS70 and CS189, and Princeton's COS432.</li> -->
            <!-- <li> I <a href="https://scet.berkeley.edu/blockchain-roundtable/">worked on R&D</a> at <a href="https://blockchain.berkeley.edu/">Blockchain at Berkeley</a>. I don't work in crypto anymore, but I'm happy to direct you to any of my amazing friends who have started companies in the space.</li> -->
            <!-- <li> I read voraciously, about <a href="https://www.goodreads.com/user/year_in_books/2021/18314561">100 books a year</a>, almost entirely fiction. My favorite genres are <a href="https://en.wikipedia.org/wiki/Xianxia">xianxia</a>, <a href="https://en.wikipedia.org/wiki/Hugo_Award_for_Best_Novel">SFF</a> and <a href ="https://www.reddit.com/r/horrorlit/">horror</a>. My favorite book is <a href="https://www.instagram.com/stories/highlights/17955811226448825/">The Brothers Karamazov</a> by Fyodor Dostoevsky. </li> -->
          <!-- </ul> -->
          </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
